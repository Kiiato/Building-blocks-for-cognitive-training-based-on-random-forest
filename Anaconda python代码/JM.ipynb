{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始袋外得分： 0.9983948635634029\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import make_scorer,accuracy_score,recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# #生成数据集\n",
    "# data_X, data_Y = datasets.make_classification(\n",
    "#     n_samples=5000,n_features=16,n_informative=12,n_redundant=0,n_classes=4,n_clusters_per_class=1,random_state=10)\n",
    "#分割训练集和测试集\n",
    "# train_X, test_X, train_y, test_y=train_test_split(data_X,data_Y,test_size=0.3,random_state=10)\n",
    "\n",
    "#输入原始数据\n",
    "data=np.loadtxt('jm_mode3.csv',dtype=int,delimiter=',',unpack=False)\n",
    "X=data[:,:17]\n",
    "y=data[:,17]\n",
    "train_X, test_X, train_y, test_y = train_test_split(X,y,test_size=0.3,random_state=10)\n",
    "\n",
    "#标准化特征数据\n",
    "ss=StandardScaler()\n",
    "train_X_new=ss.fit_transform(train_X)\n",
    "test_X_new=ss.transform(test_X)\n",
    "\n",
    "\n",
    "#实例化一个随机森林\n",
    "rfc = RandomForestClassifier(oob_score=True, random_state=10)\n",
    "rfc.fit(train_X_new,train_y)\n",
    "print ('初始袋外得分：',rfc.oob_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #pca降维\n",
    "# oob_score=[]\n",
    "# for i in range(3,16):\n",
    "#     pca = PCA(n_components=i, random_state=10)\n",
    "#     pca.fit(train_X_new)\n",
    "#     #print (pca.explained_variance_ratio_)\n",
    "#     #print (pca.explained_variance_)\n",
    "\n",
    "#     #pca降维后的模型得分\n",
    "#     train_X_new2=pca.fit_transform(train_X_new)\n",
    "#     test_X_new2=pca.transform(test_X_new)\n",
    "#     rfc.fit(train_X_new2,train_y)\n",
    "#     oob_score.append(rfc.oob_score_)\n",
    "#     print('维数：',i,'\\t袋外得分：',rfc.oob_score_)\n",
    "# print('最佳维数：',oob_score.index(max(oob_score))+3,'\\t袋外得分：',max(oob_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #最佳降维数据集\n",
    "# pca = PCA(n_components=5, random_state=10)\n",
    "# pca.fit(train_X_new)\n",
    "# train_X_new2=pca.fit_transform(train_X_new)\n",
    "# test_X_new2=pca.transform(test_X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                     params  mean_test_score\n",
       " 0     {'max_depth': 3, 'n_estimators': 100}           0.9952\n",
       " 1     {'max_depth': 3, 'n_estimators': 110}           0.9936\n",
       " 2     {'max_depth': 3, 'n_estimators': 120}           0.9952\n",
       " 3     {'max_depth': 3, 'n_estimators': 130}           0.9936\n",
       " 4     {'max_depth': 3, 'n_estimators': 140}           0.9936\n",
       " ..                                      ...              ...\n",
       " 175  {'max_depth': 14, 'n_estimators': 200}           0.9984\n",
       " 176  {'max_depth': 14, 'n_estimators': 210}           1.0000\n",
       " 177  {'max_depth': 14, 'n_estimators': 220}           1.0000\n",
       " 178  {'max_depth': 14, 'n_estimators': 230}           1.0000\n",
       " 179  {'max_depth': 14, 'n_estimators': 240}           1.0000\n",
       " \n",
       " [180 rows x 2 columns], {'max_depth': 6, 'n_estimators': 100}, 1.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#最优决策树数目和最大深度\n",
    "param_test1 = {'n_estimators':range(100,250,10),'max_depth':range(3,15,1)}\n",
    "gsearch1 = GridSearchCV(estimator = RandomForestClassifier(random_state=10),\n",
    "                        param_grid = param_test1, scoring='recall_micro',cv=5,n_jobs=-1)\n",
    "gsearch1.fit(train_X_new,train_y)\n",
    "pd.DataFrame(gsearch1.cv_results_).loc[:, ['params','mean_test_score']], gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                  params  mean_test_score\n",
       " 0    {'max_features': 1}         0.893333\n",
       " 1    {'max_features': 2}         0.920000\n",
       " 2    {'max_features': 3}         0.920000\n",
       " 3    {'max_features': 4}         0.926667\n",
       " 4    {'max_features': 5}         0.933333\n",
       " 5    {'max_features': 6}         0.933333\n",
       " 6    {'max_features': 7}         0.933333\n",
       " 7    {'max_features': 8}         0.920000\n",
       " 8    {'max_features': 9}         0.940000\n",
       " 9   {'max_features': 10}         0.940000\n",
       " 10  {'max_features': 11}         0.933333\n",
       " 11  {'max_features': 12}         0.926667\n",
       " 12  {'max_features': 13}         0.926667\n",
       " 13  {'max_features': 14}         0.920000\n",
       " 14  {'max_features': 15}         0.926667,\n",
       " {'max_features': 9},\n",
       " 0.9400000000000001)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#最大特征数\n",
    "param_test2 = {'max_features':range(1,16)}\n",
    "gsearch2 = GridSearchCV(estimator = RandomForestClassifier(n_estimators= 60,max_depth=10,random_state=10),\n",
    "                        param_grid = param_test2, scoring='recall_micro',cv=5,n_jobs=-1)\n",
    "gsearch2.fit(train_X_new,train_y)\n",
    "pd.DataFrame(gsearch2.cv_results_).loc[:, ['params','mean_test_score']], gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机森林袋外得分： 0.9983948635634029\n",
      "*****************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       220\n",
      "           2       1.00      1.00      1.00        25\n",
      "           3       1.00      1.00      1.00        23\n",
      "\n",
      "    accuracy                           1.00       268\n",
      "   macro avg       1.00      1.00      1.00       268\n",
      "weighted avg       1.00      1.00      1.00       268\n",
      "\n",
      "*****************************************************\n"
     ]
    }
   ],
   "source": [
    "# 模型评估\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators= 100,max_depth=6,oob_score=True, random_state=10)\n",
    "rfc.fit(train_X_new,train_y)\n",
    "print('随机森林袋外得分：',rfc.oob_score_)\n",
    "\n",
    "#对最终模型进行评估\n",
    "test_y_pred=rfc.predict(test_X_new)\n",
    "confusion_mat = confusion_matrix(test_y,test_y_pred)\n",
    "#print(confusion_mat) #看看混淆矩阵长啥样\n",
    "print('*'*53)\n",
    "print(classification_report(test_y,test_y_pred))\n",
    "print('*'*53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rfc_mode3.m']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 打包\n",
    "joblib.dump(rfc, \"rfc_mode3.m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "袋外得分： 0.9322857142857143\n"
     ]
    }
   ],
   "source": [
    "#第一次调参后的检验，可不加\n",
    "rfc = RandomForestClassifier(n_estimators= 220,oob_score=True,random_state=10)\n",
    "rfc.fit(train_X_new,train_y)\n",
    "print('袋外得分：',rfc.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                        params  mean_test_score\n",
       " 0    {'max_depth': 11, 'min_samples_split': 2}         0.927143\n",
       " 1    {'max_depth': 11, 'min_samples_split': 4}         0.924000\n",
       " 2    {'max_depth': 11, 'min_samples_split': 6}         0.928000\n",
       " 3    {'max_depth': 11, 'min_samples_split': 8}         0.921714\n",
       " 4   {'max_depth': 11, 'min_samples_split': 10}         0.922286\n",
       " 5    {'max_depth': 13, 'min_samples_split': 2}         0.931714\n",
       " 6    {'max_depth': 13, 'min_samples_split': 4}         0.925429\n",
       " 7    {'max_depth': 13, 'min_samples_split': 6}         0.928571\n",
       " 8    {'max_depth': 13, 'min_samples_split': 8}         0.927429\n",
       " 9   {'max_depth': 13, 'min_samples_split': 10}         0.924571\n",
       " 10   {'max_depth': 15, 'min_samples_split': 2}         0.930286\n",
       " 11   {'max_depth': 15, 'min_samples_split': 4}         0.927429\n",
       " 12   {'max_depth': 15, 'min_samples_split': 6}         0.928571\n",
       " 13   {'max_depth': 15, 'min_samples_split': 8}         0.927429\n",
       " 14  {'max_depth': 15, 'min_samples_split': 10}         0.922857\n",
       " 15   {'max_depth': 17, 'min_samples_split': 2}         0.928857\n",
       " 16   {'max_depth': 17, 'min_samples_split': 4}         0.927714\n",
       " 17   {'max_depth': 17, 'min_samples_split': 6}         0.928857\n",
       " 18   {'max_depth': 17, 'min_samples_split': 8}         0.926286\n",
       " 19  {'max_depth': 17, 'min_samples_split': 10}         0.922286\n",
       " 20   {'max_depth': 19, 'min_samples_split': 2}         0.928857\n",
       " 21   {'max_depth': 19, 'min_samples_split': 4}         0.926286\n",
       " 22   {'max_depth': 19, 'min_samples_split': 6}         0.928571\n",
       " 23   {'max_depth': 19, 'min_samples_split': 8}         0.928857\n",
       " 24  {'max_depth': 19, 'min_samples_split': 10}         0.922571,\n",
       " {'max_depth': 13, 'min_samples_split': 2},\n",
       " 0.9317142857142857)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#最大深度和最小分割样本数\n",
    "param_test2 = {'max_depth':range(11,20,2), 'min_samples_split':range(2,11,2)}\n",
    "#Scoring = ['recall_micro','f1_micro']\n",
    "gsearch2 = GridSearchCV(estimator = RandomForestClassifier(n_estimators= 220,random_state=10),\n",
    "                        param_grid = param_test2, scoring='recall_micro',cv=5,n_jobs=-1)\n",
    "gsearch2.fit(train_X_new,train_y)\n",
    "pd.DataFrame(gsearch2.cv_results_).loc[:, ['params','mean_test_score']], gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                              params  mean_test_score\n",
       " 0    {'min_samples_leaf': 1, 'min_samples_split': 2}         0.929143\n",
       " 1    {'min_samples_leaf': 1, 'min_samples_split': 4}         0.924000\n",
       " 2    {'min_samples_leaf': 1, 'min_samples_split': 6}         0.927143\n",
       " 3    {'min_samples_leaf': 1, 'min_samples_split': 8}         0.928571\n",
       " 4   {'min_samples_leaf': 1, 'min_samples_split': 10}         0.924857\n",
       " 5    {'min_samples_leaf': 3, 'min_samples_split': 2}         0.923714\n",
       " 6    {'min_samples_leaf': 3, 'min_samples_split': 4}         0.923714\n",
       " 7    {'min_samples_leaf': 3, 'min_samples_split': 6}         0.923714\n",
       " 8    {'min_samples_leaf': 3, 'min_samples_split': 8}         0.923143\n",
       " 9   {'min_samples_leaf': 3, 'min_samples_split': 10}         0.922286\n",
       " 10   {'min_samples_leaf': 5, 'min_samples_split': 2}         0.915143\n",
       " 11   {'min_samples_leaf': 5, 'min_samples_split': 4}         0.915143\n",
       " 12   {'min_samples_leaf': 5, 'min_samples_split': 6}         0.915143\n",
       " 13   {'min_samples_leaf': 5, 'min_samples_split': 8}         0.915143\n",
       " 14  {'min_samples_leaf': 5, 'min_samples_split': 10}         0.915143\n",
       " 15   {'min_samples_leaf': 7, 'min_samples_split': 2}         0.912286\n",
       " 16   {'min_samples_leaf': 7, 'min_samples_split': 4}         0.912286\n",
       " 17   {'min_samples_leaf': 7, 'min_samples_split': 6}         0.912286\n",
       " 18   {'min_samples_leaf': 7, 'min_samples_split': 8}         0.912286\n",
       " 19  {'min_samples_leaf': 7, 'min_samples_split': 10}         0.912286\n",
       " 20   {'min_samples_leaf': 9, 'min_samples_split': 2}         0.906286\n",
       " 21   {'min_samples_leaf': 9, 'min_samples_split': 4}         0.906286\n",
       " 22   {'min_samples_leaf': 9, 'min_samples_split': 6}         0.906286\n",
       " 23   {'min_samples_leaf': 9, 'min_samples_split': 8}         0.906286\n",
       " 24  {'min_samples_leaf': 9, 'min_samples_split': 10}         0.906286,\n",
       " {'min_samples_leaf': 1, 'min_samples_split': 2},\n",
       " 0.9291428571428572)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#最小分割样本数与最小叶节点样本数\n",
    "param_test3 = {'min_samples_leaf':range(1,10,2), 'min_samples_split':range(2,11,2)}\n",
    "gsearch3 = GridSearchCV(estimator = RandomForestClassifier(n_estimators= 220,max_depth=13,random_state=10),\n",
    "                        param_grid = param_test3, scoring='recall_micro',cv=5,n_jobs=-1)\n",
    "gsearch3.fit(train_X_new,train_y)\n",
    "pd.DataFrame(gsearch3.cv_results_).loc[:, ['params','mean_test_score']], gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                  params  mean_test_score\n",
       " 0    {'max_features': 1}         0.903143\n",
       " 1    {'max_features': 2}         0.923429\n",
       " 2    {'max_features': 3}         0.926000\n",
       " 3    {'max_features': 4}         0.929143\n",
       " 4    {'max_features': 5}         0.932286\n",
       " 5    {'max_features': 6}         0.931714\n",
       " 6    {'max_features': 7}         0.930286\n",
       " 7    {'max_features': 8}         0.929714\n",
       " 8    {'max_features': 9}         0.926000\n",
       " 9   {'max_features': 10}         0.930571\n",
       " 10  {'max_features': 11}         0.926857\n",
       " 11  {'max_features': 12}         0.924000\n",
       " 12  {'max_features': 13}         0.922286\n",
       " 13  {'max_features': 14}         0.923143\n",
       " 14  {'max_features': 15}         0.920286,\n",
       " {'max_features': 5},\n",
       " 0.9322857142857142)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#最大特征数\n",
    "param_test4 = {'max_features':range(1,16)}\n",
    "gsearch4 = GridSearchCV(estimator = RandomForestClassifier(n_estimators= 220,max_depth=13,min_samples_leaf=1,min_samples_split=2,random_state=10),\n",
    "                        param_grid = param_test4, scoring='recall_micro',cv=5,n_jobs=-1)\n",
    "gsearch4.fit(train_X_new,train_y)\n",
    "pd.DataFrame(gsearch4.cv_results_).loc[:, ['params','mean_test_score']], gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn得分 0.9286666666666666\n",
      "逻辑回归得分 0.842\n",
      "朴素贝叶斯得分 0.8186666666666667\n",
      "支持向量机得分:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       383\n",
      "           1       0.96      0.93      0.95       383\n",
      "           2       0.91      0.92      0.92       368\n",
      "           3       0.92      0.91      0.91       366\n",
      "\n",
      "    accuracy                           0.93      1500\n",
      "   macro avg       0.93      0.93      0.93      1500\n",
      "weighted avg       0.93      0.93      0.93      1500\n",
      "\n",
      "**************************************************\n",
      "随机森林袋外得分： 0.9305714285714286\n",
      "**************************************************\n",
      "[[358   5  14   6]\n",
      " [  6 358   8  11]\n",
      " [ 15   4 337  12]\n",
      " [  8   7  10 341]]\n",
      "**************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       383\n",
      "           1       0.96      0.93      0.95       383\n",
      "           2       0.91      0.92      0.91       368\n",
      "           3       0.92      0.93      0.93       366\n",
      "\n",
      "    accuracy                           0.93      1500\n",
      "   macro avg       0.93      0.93      0.93      1500\n",
      "weighted avg       0.93      0.93      0.93      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# #支持向量机调参\n",
    "# param_test5 = {'C':np.arange(1,2.5,0.2),'gamma':np.arange(0.02,0.026,0.001)}\n",
    "# gsearch5 = GridSearchCV(estimator = SVC(kernel='rbf',decision_function_shape='ovr'),\n",
    "#                         param_grid = param_test5, scoring='recall_micro',cv=5,n_jobs=-1)\n",
    "# gsearch5.fit(train_X_new,train_y)\n",
    "# print(pd.DataFrame(gsearch5.cv_results_).loc[:, ['params','mean_test_score']], gsearch5.best_params_, gsearch5.best_score_)\n",
    "svc=SVC(C=1.8,gamma=0.021,kernel='rbf',decision_function_shape='ovr')\n",
    "\n",
    "# #逻辑回归调参\n",
    "# param_test6 = {'C':np.arange(0.05,0.5,0.01),'penalty':['l1','l2']}\n",
    "# gsearch6 = GridSearchCV(estimator = LogisticRegression(solver = \"liblinear\"),\n",
    "#                         param_grid = param_test6, scoring='recall_micro',cv=5,n_jobs=-1)\n",
    "# gsearch6.fit(train_X_new,train_y)\n",
    "# print(pd.DataFrame(gsearch6.cv_results_).loc[:, ['params','mean_test_score']], gsearch6.best_params_, gsearch6.best_score_)\n",
    "lr=LogisticRegression(solver = \"liblinear\",C=0.11,penalty='l1')\n",
    "\n",
    "# #knn调参\n",
    "# param_test7 = {'n_neighbors':range(15,30,1),'p':range(1,6,1)}\n",
    "# gsearch7 = GridSearchCV(estimator = KNeighborsClassifier(weights='distance'),\n",
    "#                         param_grid = param_test7, scoring='recall_micro',cv=5,n_jobs=-1)\n",
    "# gsearch7.fit(train_X_new,train_y)\n",
    "# print(pd.DataFrame(gsearch7.cv_results_).loc[:, ['params','mean_test_score']], gsearch7.best_params_, gsearch7.best_score_)\n",
    "knn=KNeighborsClassifier(n_neighbors=25,weights='distance',p=2)\n",
    "\n",
    "knn.fit(train_X_new,train_y)\n",
    "lr.fit(train_X_new,train_y)\n",
    "gnb.fit(train_X_new,train_y)\n",
    "svc.fit(train_X_new,train_y)\n",
    "print('knn得分',knn.score(test_X_new,test_y))\n",
    "print('逻辑回归得分',lr.score(test_X_new,test_y))\n",
    "print('朴素贝叶斯得分',gnb.score(test_X_new,test_y))\n",
    "test_y_pred=svc.predict(test_X_new)\n",
    "print('支持向量机得分:\\n',classification_report(test_y,test_y_pred))\n",
    "print('*'*50)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators= 220, max_depth=13, min_samples_split=2,\n",
    "                                  min_samples_leaf=1,max_features=5 ,oob_score=True, random_state=10)\n",
    "rfc.fit(train_X_new,train_y)\n",
    "print('随机森林袋外得分：',rfc.oob_score_)\n",
    "print('*'*50)\n",
    "#对最终模型进行评估\n",
    "test_y_pred=rfc.predict(test_X_new)\n",
    "confusion_mat = confusion_matrix(test_y,test_y_pred)\n",
    "print(confusion_mat) #看看混淆矩阵长啥样\n",
    "print('*'*50)\n",
    "print(classification_report(test_y,test_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
